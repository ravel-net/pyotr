import random_graph
import pprint
import sys
import psycopg2
from os.path import dirname, abspath, join
root = dirname(dirname(abspath(__file__)))
filename = join(root, 'util/check_tautology')
sys.path.append(filename)
filename = join(root, 'faure_translator')
sys.path.append(filename)
import translator
import check_tautology

host = '127.0.0.1'
user = 'postgres'
password = 'mubashir'
database = 'test'

def generatePaths(vertices, probability_of_edge, depth, tries):
	g = random_graph.RandomGraph(vertices, probability_of_edge)
	print("Adj Matrix")
	g.printAdjMatrix()
	paths = g.randomPaths(0, g.n - 1, depth, tries) # generates random paths between two nodes
	print("paths:", paths)
	print("length of paths:", len(paths))
	return paths

def value(pre_processed_val, constants):
	if pre_processed_val in constants:
		return str(pre_processed_val)
	else:
		return "x" + str(pre_processed_val)

def generateOneBigSwitchTopo(vertices, probability_of_edge, depth, tries):
	paths = generatePaths(vertices, probability_of_edge, depth, tries)
	pathNum = 0
	allPaths = []
	for path in paths:
		pathNum += 1
		curr_path = []
		for i in range(0, len(path)-1):
			f = "f"+str(pathNum)
			n1 = value(path[i], [0, vertices-1])
			n2 = value(path[i+1], [0, vertices-1])
			newTuple = (f, n1, n2)
			curr_path.append(newTuple)
		allPaths.append(curr_path)
	return allPaths

def convert_tableau_to_sql_one_big(tableaus, tablename, overlay_nodes):
    """
    Convert tableau to corresponding SQL

    Parameters:
    ------------
    tableau : list 
        The tableau tuples(non self-connected) and self-connected tuples in forwarding order, 
        generated by gen_tableau() function (tuples + self_tuples) or retrieved from database table.
        For example, path 1 -> 2 -> 3, the tableau tuples are [(1, 5, {}), (5, 2, {}), (2, 3, {}), (1, 1, {}), (2, 2, {})], 
        node 2 is split into 2 and 5(interface, calculated by adding 2 and the max value among the virtual nodes, here is 3).

    tablename : string 
        The name of data table in database that stores the tableau

    overlay_nodes : list
        the list of constant nodes in overlay network

    Returns:
    ------------
    sql : string
        The sql string that can directly run in Postgres 
    """
    # cols = []
    sql_queries = []
    tableauNum = 0
    for tableau in tableaus:
	    tables = []
	    constraints = []
	    
	    last = ""
	    var_dict = {}
	    for i in range(len(tableau)):
	        tables.append("{} t{}".format(tablename, i))
	        # (n1, n2, _) = tableau[i]
	        n1 = tableau[i][1]
	        n2 = tableau[i][2]

	        if n1.isdigit():
	            # if n1 in overlay_nodes or str(int(n1)-max_val) in overlay_nodes:
	            #     if n1 != n2 and n1 != last:
	            #         # cols.append("t{}.n1".format(i))
	            #         cols.append(n1)
	            constraints.append("t{}.n1 = '{}'".format(i, n1))
	        
	        if n2.isdigit():
	            # if n2 in overlay_nodes or str(int(n2)-max_val) in overlay_nodes:
	            #     if n1 != n2:
	            #         # cols.append("t{}.n2".format(i))
	            #         cols.append(n2)
	            constraints.append("t{}.n2 = '{}'".format(i, n2))

	        if n1 == last and not n1.isdigit():
	            constraints.append("t{}.n2 = t{}.n1".format(i-1, i))
	            var_dict[n1] = i

	        if not n1.isdigit() and not n2.isdigit() and n1 == n2:
	            constraints.append("t{}.n1 = t{}.n2".format(i, i))
	            if n1 in var_dict.keys():
	                constraints.append("t{}.n1 = t{}.n2".format(var_dict[n1], i))

	        if n1 == last:
	        	constraints.append("t{}.fid = t{}.fid".format(i-1, i))

	        last = n2
	    # print(cols)
	    # print(tables)
	    # print(constraints)
	    sql = "select " + ", ".join(overlay_nodes[tableauNum]) + " from " + ", ".join(tables) + " where " + " and ".join(constraints)
	    sql_queries.append(sql)
	    print(sql)
	    tableauNum += 1
    # final_query = " UNION ALL ".join(sql_queries)
    final_query = sql_queries
    return final_query



if __name__ == "__main__":
	# vertices = 10
	# probability_of_edge = 0.3
	# depth = 40
	# tries = 10
	# tableName = "bigSwitch"
	# allPaths = generateOneBigSwitchTopo(vertices, probability_of_edge, depth, tries)
	# pp = pprint.PrettyPrinter(indent=4)
	# pp.pprint(allPaths)
	
	conn = psycopg2.connect(host=host,user=user,password=password,database=database)
	# f1 = [("f1",'0','x'),("f1",'x','y'),("f1",'y','2')]
	f2 = [("f2",'0','x'),("f2",'x','z'),("f2",'y','z'),("f2",'y','2')]
	# f2 = [("f2",'0','x'),("f2",'x','z'),("f2",'y','z')]
	allPaths = []
	# allPaths.append(f1)
	allPaths.append(f2)
	pp = pprint.PrettyPrinter(indent=4)
	pp.pprint(allPaths)
	# convert_tableau_to_sql(allPaths, "t_v", [['f1', '0', 'str(vertices-1)'], ['f2', '0', str(vertices-1)]])
	# sql_query = convert_tableau_to_sql_one_big(allPaths, "t_v", [['f1', '0', '2'], ['f2', '0', '2']])
	sql_query = ["SELECT f2, 0, 2 FROM t_v t0, t_v t1, t_v t2, t_v t3 WHERE t0.n1 = '0' AND t0.n2 = t1.n1 AND t0.fid = t1.fid AND t1.n2 = t2.n2 AND t1.fid = t2.fid AND t3.n2 = '2' AND t2.n1 = t3.n1 AND t2.fid = t3.fid"]
	print(sql_query)
	for sql in sql_query:
		print(sql)
		tree = translator.generate_tree(sql)
		dat = translator.data(tree)
		upd_time = translator.upd_condition(tree)
		# nor_time = translator.normalization()
		conn.close()
		conn = psycopg2.connect(host=host,user=user,password=password,database=database)
		cur = conn.cursor()
		if (check_tautology.table_contains_answer("output", ["1"], ["v"])):
			print("TRUE")
		conn.commit()
		conn.close()
